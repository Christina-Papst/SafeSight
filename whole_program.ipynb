{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import PIL.Image\n",
    "import cv2\n",
    "import torch\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "import re\n",
    "from random import randint\n",
    "import pandas as pd\n",
    "import requests\n",
    "import os\n",
    "import shutil\n",
    "import hashlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel\n",
    "from transformers import AutoModelForImageClassification, ViTImageProcessor\n",
    "from transformers import ViTFeatureExtractor, ViTForImageClassification, AutoImageProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chpap\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\vit\\feature_extraction_vit.py:28: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# this model checks if the image is unsafe for work\n",
    "MODEL = AutoModelForImageClassification.from_pretrained(\"Falconsai/nsfw_image_detection\")\n",
    "PROCESSOR = ViTImageProcessor.from_pretrained('Falconsai/nsfw_image_detection')\n",
    "\n",
    "# this model gives an age range for a person on the picture\n",
    "model = ViTForImageClassification.from_pretrained('nateraw/vit-age-classifier')\n",
    "transforms = ViTFeatureExtractor.from_pretrained('nateraw/vit-age-classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_image(image_path):\n",
    "    \n",
    "    # Load the image\n",
    "    img = PIL.Image.open(image_path)\n",
    "    \n",
    "    # Process the image and make predictions if the image is nsfw\n",
    "    with torch.no_grad():\n",
    "        inputs = PROCESSOR(images=img, return_tensors=\"pt\")\n",
    "        outputs = MODEL(**inputs)\n",
    "        logits = outputs.logits\n",
    "    \n",
    "    # Get the predicted label\n",
    "    predicted_label = logits.argmax(-1).item()\n",
    "    \n",
    "    # Map the predicted label to its corresponding class name\n",
    "    label_map = MODEL.config.id2label\n",
    "    predicted_class = label_map[predicted_label]\n",
    "\n",
    "     # this part is classifying the age of the person on the picture\n",
    "    model = ViTForImageClassification.from_pretrained('nateraw/vit-age-classifier')\n",
    "    transforms = ViTFeatureExtractor.from_pretrained('nateraw/vit-age-classifier')\n",
    "    inputs = transforms(img, return_tensors='pt')\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "    proba = outputs.logits.softmax(1)\n",
    "    preds = proba.argmax(1)\n",
    "\n",
    "    id_to_age_range = {\n",
    "        0: \"0-2\",\n",
    "        1: \"3-9\",\n",
    "        2: \"10-19\",\n",
    "        3: \"20-29\",\n",
    "        4: \"30-39\",\n",
    "        5: \"40-49\",\n",
    "        6: \"50-59\",\n",
    "        7: \"60-69\",\n",
    "        8: \"more than 70\"\n",
    "}\n",
    "\n",
    "    # Convert predicted class indices to age ranges\n",
    "    predicted_age_ranges = [id_to_age_range[pred.item()] for pred in preds]\n",
    "\n",
    "    # this part identifies the most prevalent emotion\n",
    "    image_processor = AutoImageProcessor.from_pretrained(\"dima806/facial_emotions_image_detection\")\n",
    "    model = ViTForImageClassification.from_pretrained(\"dima806/facial_emotions_image_detection\")\n",
    "\n",
    "    image = PIL.Image.open(image_path)\n",
    "    image = np.array(image)\n",
    "    image = image[:, :, :3]\n",
    "\n",
    "    inputs = image_processor(image, return_tensors=\"pt\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "\n",
    "    predicted_emotion = logits.argmax(-1).item()\n",
    "\n",
    "    # Check if NSFW and age is less than 20\n",
    "    if predicted_class == \"nsfw\" and any(age_range in [\"0-2\", \"3-9\", \"10-19\"] for age_range in predicted_age_ranges):\n",
    "    # Copy the image to the flagged folder\n",
    "        shutil.copy2(image_path, directory=\"flagged_images\")\n",
    "   \n",
    "    nsfw_negative_emotions = [\"sad\", \"disgust\", \"angry\", \"fear\"]  # List of negative emotions\n",
    "\n",
    "    if predicted_class == \"nsfw\" and any(predicted_emotion == emotion for emotion in nsfw_negative_emotions):\n",
    "    # Copy the image to the flagged folder\n",
    "        shutil.copy2(image_path, flagged_folder_path)\n",
    "    \n",
    "\n",
    "    # show the results in all three categories\n",
    "    print(\"Safe or unsafe for work:\", predicted_class)\n",
    "    print(\"Predicted age ranges:\", predicted_age_ranges)\n",
    "    print(\"The most prevalent emotion is\", model.config.id2label[predicted_emotion])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of fake user agents\n",
    "SCRAPEOPS_API_KEY = '0e81eee1-3ea8-4fcd-95fd-cbc2ef81daee'\n",
    "\n",
    "def get_user_agent_list():\n",
    "  response = requests.get('http://headers.scrapeops.io/v1/user-agents?api_key=' + SCRAPEOPS_API_KEY)\n",
    "  json_response = response.json()\n",
    "  return json_response.get('result', [])\n",
    "\n",
    "def get_random_user_agent(user_agent_list):\n",
    "  random_index = randint(0, len(user_agent_list) - 1)\n",
    "  return user_agent_list[random_index]\n",
    "\n",
    "## Retrieve User-Agent List From ScrapeOps\n",
    "user_agent_list = get_user_agent_list()\n",
    "\n",
    "def download_images(url, directory=\"scraped_images\"):\n",
    "  \n",
    "\n",
    "    headers = {'User-Agent': get_random_user_agent(user_agent_list)}  # Assuming you have this function\n",
    "\n",
    "    # Create the directory if it doesn't exist\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "    response = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    img_tags = soup.find_all('img')\n",
    "\n",
    "    for img in img_tags:\n",
    "        img_url = img['src']\n",
    "\n",
    "        # Handle relative URLs by prepending the base URL\n",
    "        if img_url.startswith('http') or img_url.startswith('https'):\n",
    "            image_url = img_url\n",
    "        else:\n",
    "            image_url = url + img_url\n",
    "\n",
    "        # Generate a unique filename based on the image URL\n",
    "        filename = hashlib.sha256(image_url.encode('utf-8')).hexdigest()[:10] + \".jpg\"\n",
    "\n",
    "        # Save the image\n",
    "        with requests.get(image_url, stream=True) as image_response:\n",
    "            if image_response.status_code == 200:\n",
    "                with open(os.path.join(directory, filename), 'wb') as file:\n",
    "                    for chunk in image_response.iter_content(1024):\n",
    "                        file.write(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rate_images(url, directory=\"scraped_images\"):\n",
    "\n",
    "\n",
    "    # Download images\n",
    "    download_images(url, directory)\n",
    "\n",
    "    # Process each image in the directory\n",
    "    for filename in os.listdir(directory):\n",
    "        image_path = os.path.join(directory, filename)\n",
    "        predicted_values = classify_image(image_path)  # Call the existing classify_image function\n",
    "  \n",
    "\n",
    "        # Print the results\n",
    "        print(f\"Image: {filename}\")\n",
    "        print(predicted_values)\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://depositphotos.com/photos/sexy-fantasy.html?sorting=newest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Safe or unsafe for work: normal\n",
      "Predicted age ranges: ['20-29']\n",
      "The most prevalent emotion is fear\n",
      "Image: 0a5acb2902.jpg\n",
      "None\n",
      "\n",
      "\n",
      "Safe or unsafe for work: normal\n",
      "Predicted age ranges: ['20-29']\n",
      "The most prevalent emotion is surprise\n",
      "Image: 0b5aee546f.jpg\n",
      "None\n",
      "\n",
      "\n",
      "Safe or unsafe for work: normal\n",
      "Predicted age ranges: ['20-29']\n",
      "The most prevalent emotion is fear\n",
      "Image: 15a1634d06.jpg\n",
      "None\n",
      "\n",
      "\n",
      "Safe or unsafe for work: normal\n",
      "Predicted age ranges: ['30-39']\n",
      "The most prevalent emotion is angry\n",
      "Image: 18a5110c3b.jpg\n",
      "None\n",
      "\n",
      "\n",
      "Safe or unsafe for work: normal\n",
      "Predicted age ranges: ['20-29']\n",
      "The most prevalent emotion is neutral\n",
      "Image: 366820b276.jpg\n",
      "None\n",
      "\n",
      "\n",
      "Safe or unsafe for work: normal\n",
      "Predicted age ranges: ['20-29']\n",
      "The most prevalent emotion is sad\n",
      "Image: 5b25ba969d.jpg\n",
      "None\n",
      "\n",
      "\n",
      "Safe or unsafe for work: normal\n",
      "Predicted age ranges: ['20-29']\n",
      "The most prevalent emotion is happy\n",
      "Image: 786abd674d.jpg\n",
      "None\n",
      "\n",
      "\n",
      "Safe or unsafe for work: normal\n",
      "Predicted age ranges: ['20-29']\n",
      "The most prevalent emotion is neutral\n",
      "Image: 93e11fac5e.jpg\n",
      "None\n",
      "\n",
      "\n",
      "Safe or unsafe for work: normal\n",
      "Predicted age ranges: ['20-29']\n",
      "The most prevalent emotion is neutral\n",
      "Image: 9dd1dc80e5.jpg\n",
      "None\n",
      "\n",
      "\n",
      "Safe or unsafe for work: normal\n",
      "Predicted age ranges: ['20-29']\n",
      "The most prevalent emotion is sad\n",
      "Image: a4347af117.jpg\n",
      "None\n",
      "\n",
      "\n",
      "Safe or unsafe for work: normal\n",
      "Predicted age ranges: ['20-29']\n",
      "The most prevalent emotion is fear\n",
      "Image: aa30f23735.jpg\n",
      "None\n",
      "\n",
      "\n",
      "Safe or unsafe for work: normal\n",
      "Predicted age ranges: ['20-29']\n",
      "The most prevalent emotion is sad\n",
      "Image: ad2bc67203.jpg\n",
      "None\n",
      "\n",
      "\n",
      "Safe or unsafe for work: normal\n",
      "Predicted age ranges: ['20-29']\n",
      "The most prevalent emotion is neutral\n",
      "Image: ada6fc0723.jpg\n",
      "None\n",
      "\n",
      "\n",
      "Safe or unsafe for work: normal\n",
      "Predicted age ranges: ['20-29']\n",
      "The most prevalent emotion is neutral\n",
      "Image: b2f2794296.jpg\n",
      "None\n",
      "\n",
      "\n",
      "Safe or unsafe for work: normal\n",
      "Predicted age ranges: ['30-39']\n",
      "The most prevalent emotion is sad\n",
      "Image: bbe6e87b4d.jpg\n",
      "None\n",
      "\n",
      "\n",
      "Safe or unsafe for work: nsfw\n",
      "Predicted age ranges: ['20-29']\n",
      "The most prevalent emotion is fear\n",
      "Image: be99bffe4a.jpg\n",
      "None\n",
      "\n",
      "\n",
      "Safe or unsafe for work: normal\n",
      "Predicted age ranges: ['20-29']\n",
      "The most prevalent emotion is surprise\n",
      "Image: c5ccf0223d.jpg\n",
      "None\n",
      "\n",
      "\n",
      "Safe or unsafe for work: normal\n",
      "Predicted age ranges: ['30-39']\n",
      "The most prevalent emotion is surprise\n",
      "Image: e6eec14dd0.jpg\n",
      "None\n",
      "\n",
      "\n",
      "Safe or unsafe for work: normal\n",
      "Predicted age ranges: ['20-29']\n",
      "The most prevalent emotion is fear\n",
      "Image: e9abd993ec.jpg\n",
      "None\n",
      "\n",
      "\n",
      "Safe or unsafe for work: normal\n",
      "Predicted age ranges: ['30-39']\n",
      "The most prevalent emotion is fear\n",
      "Image: eac0132681.jpg\n",
      "None\n",
      "\n",
      "\n",
      "Safe or unsafe for work: normal\n",
      "Predicted age ranges: ['20-29']\n",
      "The most prevalent emotion is neutral\n",
      "Image: eeb88be15d.jpg\n",
      "None\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rate_images(url, directory=\"scraped_images\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
